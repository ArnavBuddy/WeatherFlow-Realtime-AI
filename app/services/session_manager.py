from fastapi import WebSocket
from typing import Dict
from app.services import db_service, llm_service
import time
import asyncio

class SessionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.chat_sessions = {} # hold Gemini chat objects
        self.start_times = {}

    async def connect(self, websocket: WebSocket, session_id: str):
        await websocket.accept()
        self.active_connections[session_id] = websocket
        
        # Initialize DB session
        # We assume session_id is generated by client or we use the on-connect logic to create one?
        # Requirement says endpoint is /ws/session/{session_id}. 
        # If ID exists, resume? If not, create?
        # For simplicity, we try to create, if fails (PK violation), we ignore or assume it's new.
        # Actually UUID collision is rare. We'll assume the client generates a UUID or we redirect.
        # Let's assume the client sends a UUID. 
        # We should create the DB record here.
        try:
            await db_service.create_new_session(session_id=session_id, user_id="anon")
        except Exception as e:
            # Maybe it already exists, or other error. 
            print(f"Session creation warning: {e}")
            pass

        self.chat_sessions[session_id] = llm_service.llm_service.start_chat()
        self.start_times[session_id] = time.time()
        
        await db_service.log_event(session_id, "system", "Session started")

    async def disconnect(self, session_id: str):
        if session_id in self.active_connections:
            del self.active_connections[session_id]
        if session_id in self.chat_sessions:
            del self.chat_sessions[session_id]
        
        # Trigger post-processing
        duration = int(time.time() - self.start_times.get(session_id, time.time()))
        # We should probably run this as a background task
        # But here we just return info for the caller to handle
        return duration

    async def handle_message(self, session_id: str, message: str):
        chat = self.chat_sessions.get(session_id)
        ws = self.active_connections.get(session_id)
        
        if not chat or not ws:
            print(f"DEBUG: Session {session_id} not found or WS closed")
            return

        print(f"DEBUG: Received message from {session_id}: {message}")
        # Log user message
        await db_service.log_event(session_id, "user", message)

        # Stream response
        full_response = ""
        try:
             # Using the generator
            print("DEBUG: Starting LLM stream...")
            async for chunk in llm_service.llm_service.generate_stream(chat, message):
                print(f"DEBUG: Sending chunk: {len(chunk)} chars")
                await ws.send_text(chunk)
                full_response += chunk
            
            print(f"DEBUG: Stream finished. Full response length: {len(full_response)}")
            
            if not full_response or not full_response.strip():
                print("DEBUG: Response was empty or whitespace only. Sending fallback.")
                fallback = "Error: The AI returned no content. Please try again."
                await ws.send_text(fallback)
                full_response = fallback

            # Log AI response
            await db_service.log_event(session_id, "ai", full_response)
            
        except Exception as e:
            await ws.send_text(f"Error: {str(e)}")
            print(f"LLM Error: {e}")

session_manager = SessionManager()
